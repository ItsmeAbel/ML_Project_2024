Prerequistes: Installed Anaconda for the usage of environments
        - Installed all the necessary packages suchas matplotlib, scikit-learn, pandas, numpy,tensorflow, keras etc.

        Thought process in solving the assignment
Got the csv data
The data has multiple inputs and one output, making multilinear regression a good start. Also it is going to be a supervised model
So far, i don't see a need for data cleaning so i will start with it as it is. All the data seems to be numerical and non-string or float.
I will devide the data into training and testing set. 70,30 percent respectively
using anaconda to create a virutal environment for it. The env has numpy,pandas,scikit-learn and matplotlib so far.
implemented a simple multilinear regression model
implemented a simple svr model as well
output graph is similar for both
model need to be finetuned and properly tested
did some finetuning
result wasn't optimal. MSE = 0.15, MAE = 0.35. the closer it is to 1 the better, meaning this is very bad.
added graph using matplotlib
i have analayzed the output graph and am convinced this might be a classification problem instead since the output is either 1 0r 0, yes or no
going to try implementing a binary classification solution
will implement logistic regression for classification. 
logistic regression is clearly a better fitting solution. accuracy-0.73
default itteration is 100, going to increase that 500. same accuracy-0.73
going to use scalar to scale the data. accuracy decrease to 0.72
removed scaler.
added a low reguralization incase there is an overfitting. C=0.1. accuracy 0.73
tried sag and saga solvers. .72 and .71 accuracy respectively
tried different values for C. highest accuracy reached remains 0.73
decreased the data split to 60,40. which improved the accuracy to 0.76
implemented svm
tried linear kernel for decison boundary. accuracy 0.71
we have non-linear input data as seen in 'xplot.py' so tried rbf, accuracy increasd to 0.91!
also added reguralization C=3.0. accuraccy increased to 0.94! lower C lowers accuracy, higher C doesn't improve
going to implement Random forest and see if that improves anything

I have implemented a simple random forest model.
The model has already shown to be much better than svm and logistic regression
it has a 97% accuracy and the following confusion matrix
Confusion Matrix:
 [[183   5]
 [  8 182]]

 added a way to save the trained model so it can be loaded and be used for classification using Joblib
 also took out 5 random raws from the csv file so that the model can be tested on unseen data
divided the data 80/20



------------------------------------Problem 2----------------------------------------------------------------------
I've gotten the data and started with data cleaning first. The csv data is filled with numerical, string, and float values, which means that some data cleaning is required.
The string values are catagorical and need to be encoded to numerical values.
We can use either Label encoder or One Hot Encoding
Label Encoding is good for ordianl data, while One Hot encoding is good for non-ordianl data.
With Label Encoding and multilinear regression model, i get the following result
mean_squared_error :  2335.762251930094
mean_absolute_error :  38.73413494045972
R2:  0.08190315105789459
which is more or less off by root(MSE) = 48
Result with one hot enconding:
Name: credit_score, Length: 45000, dtype: int64
mean_squared_error :  2227.70672219333
mean_absolute_error :  37.89635561614918
R2:  0.12437555649218801

which has slightly better result! So i'll be using OHE data. The R2 value however shows that model is bad
- tried svr as well and it too exceptionally long time to excute
-the svr uses standard scaler to scaled down the data during training
-it also uses the rbf kernel<------------------------------------gotta learn what it does
the result however isn't any better. it is the same as multilinear regression
Mean Squared Error (MSE): 2352.952252105177
Mean Absolute Error (MAE): 38.17397622064392
R-squared (RÂ²): 0.07514643385304343

svr shows better result but takes too long to train. the improvment in accuracy isn't worth the tradeoff

i also implemented a decison tree and here are the result
Mean Squared Error: 4762.841777777778
R-squared Score: -0.8617762480146001
-the model is more or less off by 69, but the r2 value shows that decison tree performs worse than multilinear regression.

next up, random forest.
Random forest gives the following result:
Model Evaluation:
Mean Squared Error (MSE): 2461.65
Root Mean Squared Error (RMSE): 49.62
Mean Absolute Error (MAE): 39.75
R-squared (R2): 0.06
which isn't significantlly better than what we've tried so far

Next up: Neural Networks
Implemented a neural network model using the tensorflow and keras library
the model is pretty simple and uses the relu activation function
it has 4 layers including the input and output layers
i set the epoch size to 10 so i can better tweak and adjust it before choosing higher epoch sizes
so far, it gives more or less the same result as randomforest, but i will tweak the model so it becomes more accurate



